= Midterm Check In

This section summarizes the content of the class so far and provides an example
of a system that meets the midterm goals. This example is just one way to solve
the problem. It's not the only way, in fact it's not even the best way. The
example's purpose is to show you a solution that avoids common pitfalls.
Hopefully you can integrate some of the lessons of this example into your
project. 

== Overview

At this point you should have a working system that can be pulled from a git
repository and brought up with `docker-compose up`. As a reminder, the midterm
deliverables used to the project are:

* A *Front End* that interacts with the user via HTTP and communicates
  with the messaging container.
* *Messaging* (RabbitMQ) that brokers the exchange of information
  between the front end and the back end.
* *Database* (PostgreSQL, MariaDB, MySQL) that only *Back End* uses for storage
  of persistent information. All stateful information should be stored in a
  volume.
* A *Back End* that gathers information from your data sources, reads and
  writes from the database, and interacts with the messaging container.
* These four services work with each other to provide a web-based registration
  and authentication system.

The project is structured in such a way that *Front End* and *Back End*
never communicate directly and *Back End* is the only service that can
write to the *Database*:

[plantuml, "overview_compose", svg]
....
@startuml

actor Users

node frontend [
    Front End
]

node backend [
    Back End
]

node Messaging

database Database

Users <-> frontend
frontend <-> Messaging
Messaging <-> backend
backend <-> Database

@enduml
....

This allows for more scalability when we introduce replication in the second
half of the semester.

An example directory structure is shown below:

----
│   .env
│   docker-compose.yml
│
├───back_end
│       app.py
│       Dockerfile
│       requirements.txt
│
├───db
│       Dockerfile
│       setup.sql
│
└───front_end
    │   app.py
    │   Dockerfile
    │   requirements.txt
    │   wait-for-it.sh
    │
    └───templates
            base.html
            login.html
            register.html
----

TIP: Notice the `.env` file in the directory structure. docker-compose will
load environment variables from this file that you can then use in the
`docker-compose.yml` file. This keeps you from having to repeat yourself when
multiple services need the same information. For example, both *Database* and
*Back End* need to know the `POSTGRES_PASSWORD`. It also allows you to have a
single secret file that you can put in `.gitignore` to keep out of your
repository.

== Messaging

In our example, the *Messaging* can be run straight from the
https://hub.docker.com/_/rabbitmq[RabbitMQ Docker Hub image] via the
`docker-compose.yml` file, hence the absence of a `messaging` directory with a
`Dockerfile` in the directory structure. The image allows for sufficient
configuration via its environment variables. At this point it is recommended
that you still run the management interface and forward the management interface
port, 15672, so that you can see how the queues are being used. The messaging
service will be used in the
https://www.rabbitmq.com/tutorials/tutorial-six-python.html[request / reply pattern]
detailed in the diagram below:

[plantuml, "messaging", svg]
....
@startuml

node frontend [
    Front End
]

node backend [
    Back End
]

node Messaging {
    queue requests [
        Requests Queue
    ]
    queue replies [
        Reply Queues
        ----
        Client 1
        ....
        Client 2
        ....
        . . .
    ]
}

frontend --> requests : AMQP
frontend <-- replies : AMQP
backend <-- requests : AMQP
backend --> replies : AMQP

@enduml
....

Fortunately this works out-of-the-box since queue creation is handled by the
by the clients. The service simply has to be up and running to function.

The service definition in `docker-compose.yml` can be seen here:

.docker-compose.yml (excerpted)
[source,yaml]
----
include::../example/docker-compose.yml[tags=messaging]
----

Moving forward, we will migrate from a single RabbitMQ instance to a
cluster. Familiarize yourself with the
https://www.rabbitmq.com/clustering.html[RabbitMQ Clustering Guide] and then
see if you can create a three node cluster with docker-compose.footnote:[
Eventually we will want things to be more scalable than just a static, three
node cluster.] You may still be able to do this with just environment variables
in the `docker-compose.yml` file. If you need to, feel free to create new
container images in separate directories with their own Dockerfiles. There are
also plenty of good
https://github.com/harbur/docker-rabbitmq-cluster[web resources] to explore.

== Database

*Database* is responsible for storing the persistent information the system
uses. It only communicates with *Back End*.

[plantuml, "database", svg]
....
@startuml

node backend [
    Back End
]

database db [
    Database
    ----
    USERS
    ....
    . . .
]

backend <-> db

@enduml
....

In this example, *Database* creates a database and the appropriate tables _if_
the database is currently empty. This can be done by placing the SQL file that
we want executed in `/docker-entrypoint-initdb.d/` of the image. Our
`db/Dockerfile` handles copying our initialization SQL appropriately:

.db/Dockerfile
[source, Dockerfile]
----
include::../example/db/Dockerfile[]
----

.db/setup.sql
[source, SQL]
----
include::../example/db/setup.sql[]
----

The schema in this example is quite simple, consisting of a database and a
single table for holding emails and hashes. It should be noted that the `\c`
command is specific to PostgreSQL and it is the equivalent of a `USE` statement
in MySQL, meaning use that particular database.

The relevant service definition part of the `docker-compose.yml` file can be seen
here:

.docker-compose.yml (excerpted)
[source, yaml]
----
include::../example/docker-compose.yml[tags=db]
----

The database files are stored in a Docker volume named `data-volume` and the
password for our database is loaded from an environment variable defined in
`.env`.

TIP: The https://hub.docker.com/_/adminer/[adminer] image is a great way to see
what's going on in your database. It provides a web interface to many different
types of databases that can be easily accessed via port 8080. See the example
`docker-compose.yml` file for an example of its use.

Moving forward, we should begin to explore how we can implement replication to
make *Database* more scalable and resilient. Try to get a master / slave
configuration set up in a `docker-compose.yml`. How does replication help our
system? Will we need any other pieces to maximize its potential? Once again,
there are many good
https://medium.com/@2hamed/replicating-postgres-inside-docker-the-how-to-3244dc2305be[web resources]
on the topic.

== Back End

*Back End* brokers the exchange of information between *Messaging* and
*Database*. It also provides an area to perform the tasks needed to support the
complete system such as web scraping or computation. At this point, our example
does not include any of the latter and mainly focuses on storing / utilizing
authentication information in the database.

You can think of *Back End* as providing an API that is accessible through
*Messaging*. Any language can be a good choice for the *Back End* as long as it
has libraries to interface with *Database* and *Messaging*.

.Popular Libraries used by *Back End*
* Python
** https://www.psycopg.org/[psycopg2] (PostgreSQL)
** https://dev.mysql.com/doc/connector-python/en/[mysql.connector] (MySQL / MariaDB)
** https://github.com/pika/pika[pika] (RabbitMQ)
* PHP
** https://www.php.net/manual/en/book.mysqli.php[mysqli] (MySQL / MariaDB)
** https://github.com/php-amqplib/php-amqplib[php-amqplib] (RabbitMQ) 

[plantuml, "backend", svg]
....
@startuml

node "Back End" {
    rectangle dblib [
        mysql.connector / psycopg2 / mysqli
    ]
    rectangle messaginglib [
        pika / php-amqplib
    ]
}

node Messaging
database Database

messaginglib <--> Messaging : AMQP
dblib <-> Database : DB proto over TCP

@enduml
....

The code for the *Back End* example is entirely contained in `back_end/app.py`.
*Back End* starts by connecting to both *Messaging* and *Database* using the
pika and psycopg2 libraries respectively. With Docker Compose you don't know
when the services will become available so the example repeatedly attempts to
connect, waiting up to 60 seconds and
https://en.wikipedia.org/wiki/Exponential_backoff[backing off exponentially]
each time. Below is an example of typical startup output:

[source, console]
----
> docker-compose logs --tail=100 back_end | Select-String -Pattern root

back_end_1   | INFO:root:Waiting 1s...
back_end_1   | INFO:root:Connecting to the database...
back_end_1   | INFO:root:Connecting to messaging service...
back_end_1   | INFO:root:Waiting 2s...
back_end_1   | INFO:root:Connecting to the database...
back_end_1   | INFO:root:Connecting to messaging service...
back_end_1   | INFO:root:Waiting 4s...
back_end_1   | INFO:root:Connecting to the database...
back_end_1   | INFO:root:Connecting to messaging service...
back_end_1   | INFO:root:Waiting 8s...
back_end_1   | INFO:root:Connecting to the database...
back_end_1   | INFO:root:Connecting to messaging service...
back_end_1   | INFO:root:Starting consumption...
----

The example then creates the required database cursor, messaging channel,
messaging queues, and sets up a callback for messages arriving in the `requests`
queue. This is where the majority of work is performed and the function can be
seen here:

.back_end/app.py (excerpted)
[source, python]
----
include::../example/back_end/app.py[tags=process_request]
----

WARNING: Notice that psycopg2 functions are used to put variables into the SQL
statements. Do *NOT* use Python string formating to build your SQL statements.
You may be thinking that we are in *Back End* and the parameters we receive are
already https://xkcd.com/327/[sanitized] by *Front End* but this is not always
the case.

== Front End

The *Front End* can be created using any web framework, but the most popular
choices are https://www.php.net[PHP] or
https://palletsprojects.com/p/flask[Flask]. The most popular Docker Hub images
for those frameworks are link:++https://hub.docker.com/_/php++[php:apache] and
https://hub.docker.com/_/python[python] respectively. For interacting with
*Messaging* there are a few options, but groups tend to gravitate towards
https://github.com/php-amqplib/php-amqplib[php-amqplib] for PHP and
https://github.com/pika/pika[pika] for Python Flask. This is probably due to
the fact that the
https://www.rabbitmq.com/getstarted.html[documentation for RabbitMQ] references
those libraries.

[plantuml, "frontend", svg]
....
@startuml

actor Users

node "Front End" {
    rectangle messaginglib [
        php-amqplib / pika
    ]
    rectangle webframework [
        php / Flask
    ]
}

node Messaging 

Users --> webframework : HTTP
messaginglib <-> Messaging : AMQP 

@enduml
....

A custom `front_end/Dockerfile` is used for creating the image:

.front_end/Dockerfile
[source,docker]
----
include::../example/front_end/Dockerfile[]
----

A script called https://github.com/vishnubob/wait-for-it[`wait-for-it.sh`] is
included with the image. It is used
https://docs.docker.com/compose/startup-order/[as recommended by the Docker documentation]
to make sure the *Messaging* is up before *Front End* starts. This way
*Front End* will give errors to users who attempt to use it before the full
system has been brought up.

`front_end/Dockerfile` is built in the service section of the
`docker-compose.yml` file:

.docker-compose.yml (excerpted)
[source,yaml]
----
include::../example/docker-compose.yml[tags=front_end]
----

There are a few things in the `docker-compose.yml` service definition that
should be noted:

* Port `5000` needs to be forwarded as it will be accessed externally
* The `FLASK_ENV` environment variable is useful for development. It causes
  Flask to print more friendly error messages right inside the web browser.
* `front_end/` is bind mounted to `/app` in the container even though the
  `Dockerfile` copies those files to the `/app` directory when the image is
  created. This allows for easier development, the container can be running
  while you edit the files Flask is using. The development server will
  automatically restart if changes are detected.

To make communication with *Messaging* a easier, `front_end/messaging.py`
defines a `Messaging` class that initializes the connection, shuts down the
connection, and provides a send and receive function. All messages are sent to
the general `requests` queue and replies are returned via an exclusive reply
queue.

.front_end/messaging.py
[source, python]
----
include::../example/front_end/messaging.py[]
----

WARNING: Every HTTP request received by *Front End* will result in a full
connection sequence with *Messaging* which is not optimal. A 
https://github.com/eandersson/python-rabbitmq-examples/blob/master/Flask-examples/pika_async_rpc_example.py[better solution]
is to have the `Messaging` class run in its own thread and maintain a permanent
connection.

Let's take a look at a registration sequence involving the *User*, *Front End*,
and *Back End*:

[plantuml, "registration", svg]
....
@startuml

User -> "Front End": HTTP GET /register
"Front End" --> User: register.html
User -> "Front End": HTTP POST /register email password
"Front End" -> Messaging: REGISTER email hash
Messaging --> "Front End": SUCCESS or FAILURE
"Front End" --> User: redirect OR error

@enduml
....

The relevant code in `app.py` follows:

.front_end/app.py (excerpted)
[source, python]
----
include::../example/front_end/app.py[tags=register]
----

Fortunately password hashing functions are readily available in the
`werkzeug.security` module. https://palletsprojects.com/p/werkzeug/[Werkzeug]
is a WSGI utility library that Flask already uses, so we don't need to add
anything to `requirements.txt`. We can use the functions `check_password_hash`
and `generate_password_hash`.

WARNING: Do *NOT* store user passwords in cleartext. There are plenty of good
hashing options in both PHP and Python. Try to minimize systems that come in
contact with unencrypted passwords as well. In this example it is hashed before
it is even passed to the *Back End*. For the same reason, in production your
users should only be able to connect via TLS (HTTPS). This will secure the
channel between *User* and *Front End* which passes the password when the user
registers or logs in.

The `register` function will also set `email` in the user session upon
successful completion. This is akin to having a user log in automatically once
they have created an account.
https://flask.palletsprojects.com/en/1.1.x/api/#flask.session[Flask sessions]
are a good way of storing things on the client that can't be modified. They
default to a lifetime of 31 days.

A similar sequence is used to log in a user:

[plantuml, "login", svg]
....
@startuml

User -> "Front End": HTTP GET /login
"Front End" --> User: login.html
User -> "Front End": HTTP POST /login email password
"Front End" -> Messaging: GETHASH email
Messaging --> "Front End": hash OR error
"Front End" --> User: redirect OR error

@enduml
....

The relevant code in `front_end/app.py` follows:

.front_end/app.py (excerpted)
[source, python]
----
include::../example/front_end/app.py[tags=login]
----

Compared to the `register` function, handling a login is simpler. A few other
routes of interest with brief descriptions are:

* `/` - serves the `index.html`
* `/logout` - removes `email` from the user's session and redirects to `/`
* `/secret` - protected by the `@login_required` decorator (see below), serves
  `secret.html`

https://realpython.com/primer-on-python-decorators/[Python decorators] are used
for routing in Flask so it is a natural fit to use them to protect routes as
well. The `@login_required` decorator does exactly that:

.front_end/app.py (excerpted)
[source, python]
----
include::../example/front_end/app.py[tags=login_required]
----

Moving forward, we should start thinking about how we are going to transition
our development server to a production environment. The built-in Flask server is
great for testing our code but we will want to shift to something meant for
large scale use as we begin to scale up our application. Some packages to
research are https://www.nginx.com/[NGINX],
https://uwsgi-docs.readthedocs.io/en/latest/[uWSGI],
https://gunicorn.org/[gunicorn], https://www.apache.org/[Apache], and
https://modwsgi.readthedocs.io/en/develop/[mod_wsgi].

